{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 100\n",
    "encoding_dim2 = 32\n",
    "print(encoding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(784,))\n",
    "\n",
    "encoded = Dense(encoding_dim,activation='relu')(input_image)\n",
    "encoded2 = Dense(encoding_dim2, activation='relu')(encoded)\n",
    "#decoded2 = Dense(encoding_dim, activation='sigmoid')(encoded)\n",
    "decoded = Dense(784, activation='relu')(encoded2)\n",
    "enco_image = Input(shape=(100,))\n",
    "\n",
    "classification = Dense(10, activation='softmax')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input=input_image, output=decoded) \n",
    "classifier = Model(input=input_image, output= classification)\n",
    "# encocoder = Model(input=input_image, output= encoded2)\n",
    "# encoded_img = Input(shape=(encoding_dim2,))\n",
    "# decoder_layer = autoencoder.layers[-1]\n",
    "# decoder = Model(input=encoded_img, output=decoder_layer(encoded_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss = 'mse', metrics = ['mse'])\n",
    "classifier.compile(optimizer='adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "# (x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(x_train))\n",
    "# print(np.shape(x_test))\n",
    "# print(np.shape(y_train))\n",
    "# print(np.shape(y_test))\n",
    "nb_classes = 10\n",
    "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "# x_train = x_train[:,0,0:32,0:32]\n",
    "# x_test = x_test[:,0,0:32,0:32]\n",
    "x_train = x_train.astype('float')/ 255\n",
    "x_test = x_test.astype('float')/255\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "Y_train = np_utils.to_categorical(y_train,nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test,nb_classes)\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0788 - mean_squared_error: 0.0788 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0599 - val_mean_squared_error: 0.0599\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0552 - mean_squared_error: 0.0552 - val_loss: 0.0514 - val_mean_squared_error: 0.0514\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0489 - mean_squared_error: 0.0489 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0449 - mean_squared_error: 0.0449 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0400 - mean_squared_error: 0.0400 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0312 - val_mean_squared_error: 0.0312\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0297 - val_mean_squared_error: 0.0297\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0286 - val_mean_squared_error: 0.0286\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0276 - val_mean_squared_error: 0.0276\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6fb247a390>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train,x_train,nb_epoch=50, batch_size=256, shuffle=True, validation_data=(x_train, x_train))\n",
    "# encoded_img_x = encocoder.predict(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[0.025458505249023437, 0.025458505231142042]\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# n = 20  # how many digits we will display\n",
    "# plt.figure(figsize=(20, 4))\n",
    "# for i in range(n):\n",
    "#     # display original\n",
    "# #     ax = plt.subplot(2, n, i + 1)\n",
    "# #     plt.imshow(x_test[i].reshape(28, 28))\n",
    "# #     plt.gray()\n",
    "# #     ax.get_xaxis().set_visible(False)\n",
    "# #     ax.get_yaxis().set_visible(False)\n",
    "\n",
    "#     # display reconstruction\n",
    "#     ax = plt.subplot(2, n, i + 1 + n)\n",
    "#     plt.imshow(encoded_img_x[i].reshape(8, 4))\n",
    "#     plt.gray()\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "# plt.show()\n",
    "# encoded_img_test = encocoder.predict(x_test)\n",
    "# print encoded_img_test.shape\n",
    "# print encoded_img_x.shape \n",
    "print Y_train.shape\n",
    "\n",
    "# reconstructedImage = autoencoder.predict(x_test)\n",
    "# print reconstructedImage.shape\n",
    "\n",
    "# mse = ((reconstructedImage - x_test)**2).mean(axis= None)\n",
    "# \n",
    "score = autoencoder.evaluate(x_test, x_test, verbose= 0)\n",
    "\n",
    "# print mse\n",
    "\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.5722 - acc: 0.8399 - val_loss: 0.2921 - val_acc: 0.9174\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.2466 - acc: 0.9281 - val_loss: 0.2467 - val_acc: 0.9242\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.1902 - acc: 0.9449 - val_loss: 0.2045 - val_acc: 0.9392\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.1596 - acc: 0.9526 - val_loss: 0.1594 - val_acc: 0.9531\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.1380 - acc: 0.9605 - val_loss: 0.1346 - val_acc: 0.9609\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.1235 - acc: 0.9641 - val_loss: 0.1110 - val_acc: 0.9683\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.1109 - acc: 0.9671 - val_loss: 0.1084 - val_acc: 0.9681\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.1008 - acc: 0.9702 - val_loss: 0.0999 - val_acc: 0.9700\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0924 - acc: 0.9728 - val_loss: 0.0864 - val_acc: 0.9741\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0854 - acc: 0.9745 - val_loss: 0.0801 - val_acc: 0.9763\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0792 - acc: 0.9763 - val_loss: 0.0832 - val_acc: 0.9745\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0730 - acc: 0.9780 - val_loss: 0.0735 - val_acc: 0.9768\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0679 - acc: 0.9799 - val_loss: 0.0769 - val_acc: 0.9756\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0642 - acc: 0.9805 - val_loss: 0.0819 - val_acc: 0.9738\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0599 - acc: 0.9820 - val_loss: 0.0631 - val_acc: 0.9807\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0563 - acc: 0.9827 - val_loss: 0.0566 - val_acc: 0.9827\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0522 - acc: 0.9841 - val_loss: 0.0469 - val_acc: 0.9860\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s - loss: 0.0490 - acc: 0.9852 - val_loss: 0.0490 - val_acc: 0.9854\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0467 - acc: 0.9858 - val_loss: 0.0455 - val_acc: 0.9860\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0439 - acc: 0.9865 - val_loss: 0.0394 - val_acc: 0.9882\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0412 - acc: 0.9877 - val_loss: 0.0348 - val_acc: 0.9903\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0398 - acc: 0.9879 - val_loss: 0.0436 - val_acc: 0.9864\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0369 - acc: 0.9892 - val_loss: 0.0363 - val_acc: 0.9890\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s - loss: 0.0351 - acc: 0.9893 - val_loss: 0.0306 - val_acc: 0.9916\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0330 - acc: 0.9903 - val_loss: 0.0281 - val_acc: 0.9920\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0314 - acc: 0.9907 - val_loss: 0.0257 - val_acc: 0.9929\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0299 - acc: 0.9910 - val_loss: 0.0288 - val_acc: 0.9918\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0279 - acc: 0.9921 - val_loss: 0.0275 - val_acc: 0.9917\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0263 - acc: 0.9927 - val_loss: 0.0214 - val_acc: 0.9947\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0254 - acc: 0.9922 - val_loss: 0.0230 - val_acc: 0.9936\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0238 - acc: 0.9934 - val_loss: 0.0214 - val_acc: 0.9942\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0222 - acc: 0.9940 - val_loss: 0.0191 - val_acc: 0.9952\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0210 - acc: 0.9941 - val_loss: 0.0188 - val_acc: 0.9950\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0195 - acc: 0.9951 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0365 - val_acc: 0.9871\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0176 - acc: 0.9953 - val_loss: 0.0224 - val_acc: 0.9932\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0165 - acc: 0.9958 - val_loss: 0.0166 - val_acc: 0.9954\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0156 - acc: 0.9959 - val_loss: 0.0148 - val_acc: 0.9960\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0147 - acc: 0.9962 - val_loss: 0.0144 - val_acc: 0.9964\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0137 - acc: 0.9965 - val_loss: 0.0182 - val_acc: 0.9946\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0149 - val_acc: 0.9959\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0122 - acc: 0.9969 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0103 - val_acc: 0.9975\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0110 - acc: 0.9976 - val_loss: 0.0114 - val_acc: 0.9969\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0098 - val_acc: 0.9978\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0085 - acc: 0.9983 - val_loss: 0.0060 - val_acc: 0.9992\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0074 - val_acc: 0.9987\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s - loss: 0.0074 - acc: 0.9986 - val_loss: 0.0059 - val_acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6fb14b04d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, Y_train, nb_epoch=50, batch_size=256, verbose=1 , validation_data=(x_train, Y_train))\n",
    "# encoded_img_y = encocoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.082251969138391903, 0.97950000000000004]\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(x_test, Y_test, verbose= 0)\n",
    "print score\n",
    "\n",
    "# y_scored = np_utils.categorical_probas_to_classes(classifier.predict(x_test))\n",
    "# print y_scored\n",
    "# y2_scored = np_utils.categorical_probas_to_classes(Y_test)\n",
    "# print y2_scored"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": false,
   "summary": "Deep Asymmetrical Autoencoder based Classification of MNIST handwritten dataset"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
